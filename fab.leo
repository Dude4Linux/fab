<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet ekr_test?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.5">
	<global_window_position top="0" left="0" height="709" width="1143"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="zaril.20110904173229" a="E"><vh>Project</vh>
<v t="loni.20111001190214" a="E"><vh>documentation</vh>
<v t="zaril.20120206010821"><vh>overview</vh></v>
<v t="zaril.20120206010821.1"><vh>terminology</vh></v>
<v t="zaril.20120206010821.2"><vh>cli</vh></v>
<v t="zaril.20120206010657"><vh>inheriting from product.mk</vh></v>
<v t="zaril.20120209024252" a="E"><vh>product configuration</vh>
<v t="zaril.20120209024252.1"><vh>background</vh></v>
<v t="zaril.20120209024252.2"><vh>overview</vh></v>
<v t="zaril.20120209024252.3"><vh>conf.d/ chroot scripts</vh></v>
<v t="zaril.20120209024252.4"><vh>product configuration variables</vh></v>
</v>
</v>
<v t="loni.20111001190214.2" a="E"><vh>development log</vh>
<v t="loni.20111001190214.3" a="E"><vh>v0.5 - initial release</vh>
<v t="zaril.20110904173337"><vh>design</vh>
<v t="zaril.20110904173337.1"><vh>brainstorming</vh></v>
<v t="zaril.20110904173337.3"><vh>terminology</vh></v>
<v t="zaril.20110904173519"><vh>high-level sketch</vh></v>
<v t="zaril.20110904173337.4"><vh>cli syntax + psuedo-logic</vh>
<v t="loni.20110911164714"><vh>fab-cpp</vh></v>
<v t="loni.20110911164714.1"><vh>fab-plan-resolve</vh>
<v t="loni.20110911164714"><vh>fab-cpp</vh></v>
</v>
<v t="loni.20110911164714.2"><vh>fab-spec-install</vh></v>
<v t="loni.20110911164714.3"><vh>fab-apply-removelist</vh></v>
<v t="loni.20110910191100.1"><vh>fab-apply-overlay</vh></v>
<v t="loni.20110911164714.5"><vh>fab-plan-lint</vh></v>
</v>
<v t="loni.20110910182617"><vh>exemplary make flow</vh>
<v t="loni.20110910182756"><vh>bootstrap</vh></v>
<v t="loni.20110910182756.1"><vh>root.spec</vh>
<v t="loni.20110911164714.1" a="E"><vh>fab-plan-resolve</vh>
<v t="loni.20110911164714"><vh>fab-cpp</vh></v>
</v>
</v>
<v t="loni.20110910182756.2"><vh>root.build</vh>
<v t="loni.20110911164714.2"><vh>fab-spec-install</vh></v>
</v>
<v t="loni.20110910182756.3"><vh>root.patched</vh>
<v t="loni.20110911164714.3"><vh>fab-apply-removelist</vh></v>
<v t="loni.20110910191100.1"><vh>fab-apply-overlay</vh></v>
</v>
<v t="loni.20110910182756.4"><vh>cdroot</vh>
<v t="loni.20110910191100.1"><vh>fab-apply-overlay</vh></v>
</v>
<v t="loni.20110910182756.5"><vh>product.iso</vh></v>
</v>
</v>
<v t="zaril.20110904181421"><vh>implementation</vh>
<v t="zaril.20110904173337.5"><vh>design exercise: port backstage to fab redesign</vh>
<v t="zaril.20110904173337.6"><vh>explore make</vh>
<v t="zaril.20110904173337.7"><vh>test: directory targets</vh></v>
</v>
</v>
<v t="loni.20110911180234"><vh>fab-cpp</vh>
<v t="loni.20110912121610"><vh>weird: s/linux/1/</vh></v>
</v>
<v t="loni.20110912123550"><vh>fab-plan-resolve</vh>
<v t="loni.20110916154247"><vh>issue: provides/virtual</vh></v>
</v>
<v t="loni.20110917153918"><vh>fab-spec-install</vh>
<v t="loni.20110917232324"><vh>mass install</vh></v>
</v>
<v t="loni.20110919154516"><vh>fab-apply-removelist</vh></v>
<v t="loni.20110920142423"><vh>fab-apply-overlay</vh></v>
<v t="loni.20110920150432"><vh>fab-chroot</vh></v>
<v t="loni.20110920175636"><vh>old vs. new plans</vh>
<v t="loni.20110920183538"><vh>notes</vh></v>
</v>
<v t="loni.20110923145602"><vh>kernel image install anomaly</vh></v>
<v t="loni.20110928121323"><vh>optimize makefile with deck</vh></v>
</v>
</v>
<v t="loni.20111009174710" a="E"><vh>v0.6</vh>
<v t="loni.20111009174710.1"><vh>plan-resolve include bootstrap</vh></v>
<v t="loni.20111010161023"><vh>plan-resolve - interactive calculation</vh></v>
<v t="loni.20111121155941"><vh>optimizations</vh>
<v t="loni.20111121155941.1"><vh>spec-get</vh></v>
<v t="loni.20111121155941.2"><vh>plan-resolve</vh>
<v t="loni.20111121182213"><vh>caching</vh></v>
</v>
</v>
<v t="loni.20111206170905"><vh>regression testing</vh></v>
<v t="loni.20120103150913"><vh>bugfix: package installation prioritization</vh></v>
<v t="zaril.20120115022049"><vh>fab cli design amendment</vh>
<v t="loni.20120124160345"><vh>-p --pool or POOL</vh></v>
<v t="loni.20120124164315"><vh>fab-spec-install -&gt; fab-install</vh>
<v t="loni.20120124212451"><vh>cpp</vh></v>
<v t="loni.20120125090839"><vh>update</vh></v>
</v>
</v>
<v t="zaril.20120130143450.2"><vh>add stuff to dependencies</vh></v>
<v t="loni.20111121182213.1"><vh>correct handling dependencies on virtual packages</vh></v>
<v t="zaril.20120115022333"><vh>plan comments</vh>
<v t="zaril.20120204022939"><vh>support c-style comments in plan-lint</vh></v>
</v>
</v>
<v t="zaril.20120204224652" a="E"><vh>unreleased</vh>
<v t="zaril.20120206152141"><vh>research readahead</vh></v>
<v t="zaril.20120204233609"><vh>refactor chroot </vh></v>
<v t="zaril.20120207045734"><vh>hack fab-chroot to support environment variables</vh></v>
<v t="zaril.20120207044153" a="E"><vh>support deck inputs</vh></v>
<v t="zaril.20120115022525.1"><vh>product.mk: develop scripted configuration mechanism</vh>
<v t="zaril.20120206010049" a="E"><vh>support extension of script configuration mechanism</vh></v>
<v t="zaril.20120206033113"><vh>support symbolic links in conf.d</vh></v>
<v t="zaril.20120204224450"><vh>port casper stuff to conf.d</vh>
<v t="zaril.20120204023832"><vh>email: unnecessary or badly placed casper-bottom scripts</vh></v>
<v t="zaril.20120208012919"><vh>research casper-bottom scripts</vh></v>
<v t="zaril.20120206145455"><vh>determine what is essential to skeleton</vh>
<v t="zaril.20120207133732"><vh>port scripts</vh></v>
<v t="zaril.20120206161341" a="E"><vh>configure hostname</vh></v>
<v t="zaril.20120206161341.1" a="E"><vh>configure user/root password</vh></v>
</v>
</v>
</v>
<v t="zaril.20120115022525"><vh>allow configuration variables to influence the build process</vh></v>
<v t="zaril.20120208061751" a="E"><vh>call pool via API, not CLI</vh></v>
<v t="zaril.20120214041118" a="E"><vh>refactor get_tmpdir</vh></v>
<v t="zaril.20120208061040"><vh>dependency promotion</vh></v>
<v t="zaril.20120208060957" a="TV"><vh>fab spec dependency annotation</vh></v>
</v>
</v>
<v t="loni.20110928132411" a="E"><vh>bugs/wishlist</vh>
<v t="zaril.20120226015244" a="TV"><vh>fix fab-annotate</vh></v>
<v t="zaril.20120208061232"><vh>fab-query</vh></v>
<v t="zaril.20120208061834"><vh>intelligent handling of dependency restrictions</vh></v>
<v t="zaril.20120130153104"><vh>should Makefile show dirty changes in root.tmp?</vh></v>
<v t="zaril.20120115021505"><vh>product.mk: product recipe</vh></v>
<v t="zaril.20120115021505.1"><vh>product.mk: usb product build</vh></v>
<v t="zaril.20120115021505.2"><vh>apt -&gt; dpkg</vh></v>
<v t="loni.20111121190436"><vh>resume support?</vh></v>
<v t="zaril.20120208011925"><vh>create smallest possible bootstrap</vh></v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="loni.20110910182617"></t>
<t tx="loni.20110910182756">rm -rf bootstrap
rm -rf bootstrap.spec
cp -a /turnkey/fab/bootstraps/rocky bootstrap
cp -a /turnkey/fab/bootstraps/rocky.spec bootstrap.spec

#notes
idea:
    * use oldfab to create drop in bootstrap

This will be added to the actual bootstrap
# The linux-image package asks interactively for initial ramdisk
# creation. Therefore, we preconfigure /etc/kernel-img.conf
echo "do_initrd = Yes" &gt; ${FABPROD}/chroot/etc/kernel-img.conf

fab/bootstraps/rocky/
        cd projects/oldfab/bin
        ./10initialize
        ./15bootstrap rocky
        cp -a /turnkey/fabarea/products/chroot/* /turnkey/fab/bootstrap/rocky/

fab/bootstraps/rocky.list
        cd projects/oldfab/bin
        ./command "dpkg -l" &gt; /turnkey/fab/bootstraps/rocky.list

fab/bootstraps/rocky.spec
        cd /turnkey/fab/bootstraps
        cat rocky.list | awk '{print $2"="$3}' &gt; rocky.spec


</t>
<t tx="loni.20110910182756.1">fab-plan-resolve /turnkey/fab/pools/rocky plan/main bootstrap &gt; root.spec


# notes
fab-plan-resolve [ -options ] &lt;pool&gt; &lt;plan&gt; [ /path/to/bootstrap ]


package=version

a spec := a set of (package name, package version) tuples
    a spec is created from a plan against a specific pool
        the same plan will generate different specs against different pools
        
- parse plan for packages
- create set construct of packages=version tuples for all packages, and their deps recursively
  by querying the pool

deps?
    in order to create the root.spec, the product plan is resolved against a pool
    resolving requires getting the version and dependencies of packages, recursively
    Q: how do we get the version and deps of packages? (problem being deps)
    
    alternatives:
        patch pool-list to have -depends option
            not good option, its not pools objective to get that info
            
        generate an index on the pool, an parse it
            directly indexing the pool is not an actual option, we would have to follow $pool/.pool/stocks
            and will only get the binary deps, not the sources
            
        pool-get all packages into a temp directory, index temp, parse the index and repeat
            kludgy...
            
        pool-get each package, extract and parse control file, do the same for each dep, continue...
            IDEA: we could use the outdir to optimize the root.build, but
                  pre-mature optimization is the root of all evil
                  and besides, pool-get shouldn't be expensive, its just a hardlink
        
Q: what is bootstrap for? we have the spec anyway?
   HYPO: plan packages depend on packages installed in the bootstrap, so we dont need to get them again...
   
Q: should the root.spec include packages already installed in the bootstrap?
   ie. should the spec be dependent on the bootstrap?
A: the root.spec should _NOT_ include bootstrap packages, together the bootstrap.spec and root.spec could be used to (almost) reasemble a product.

</t>
<t tx="loni.20110910182756.2">rm -rf root.build
cp -a bootstrap root.build
fab-spec-install /turnkey/fab/pools/rocky root.spec root.build

</t>
<t tx="loni.20110910182756.3">rm -rf root.patched
cp -a root.build root.patched
fab-apply-removelist removelist root.patched
fab-apply-overlay overlay root.patched



reminder for removelist:
    post removal: in-chroot /etc/cron.daily/slocate
    
    </t>
<t tx="loni.20110910182756.4">rm -rf cdroot
cp -a /turnkey/fab/cdroots/bootsplash cdroot
fab-apply-overlay cdroot.overlay cdroot
cp root.patched/usr/lib/syslinux/isolinux.bin cdroot/isolinux
cp root.patched/boot/vmlinuz-* cdroot/casper/vmlinuz
cp root.patched/boot/initrd.img-* cdroot/casper/initrd.gz
mksquashfs root.patched cdroot/casper/filesystem.squashfs

</t>
<t tx="loni.20110910182756.5">mkisofs -o product.iso -r -J -l \
                -V backstage \
                -b isolinux/isolinux.bin \
                -c isolinux/boot.cat \
                -no-emul-boot \
                -boot-load-size 4 \
                -boot-info-table cdroot/
</t>
<t tx="loni.20110910191100.1">* fab-apply-overlay &lt;overlay&gt; &lt;path&gt;
copy &lt;overlay&gt; over &lt;path&gt;
</t>
<t tx="loni.20110911164714">* fab-cpp &lt;plan&gt; # Internal command
pre-process a plan (light wrapper around cpp)

&lt;plan&gt; := /path/to/plan | -
    if `-' read plan from stdin

options
    -D
    -I
    (passed on to CPP)

logic
    add FAB_PLAN_INCLUDE_PATH to includes
    create list of options from our cli arguments
    executes cpp, passing list options directly</t>
<t tx="loni.20110911164714.1">* fab-plan-resolve [ -options ] &lt;pool&gt; &lt;plan&gt; [ /path/to/bootstrap ]
resolves a plan into a spec that uses the latest packages from a given pool

&lt;pool&gt; := relative/path | /absolute/path
    if relative/path, pool is looked up in FAB_POOL_PATH

&lt;plan&gt; := /path/to/plan | -
    if `-' read plan from stdin

environment variables
    FAB_TMPDIR env var
        defaults to TMPDIR or /var/tmp if not set

    FAB_POOL_PATH               lookup paths for a relative pool path
        e.g.,
            FAB_POOL_PATH=/turnkey/fab/pools

options
    -o path/to/spec-output
        by default we print spec to stdout

    [ fab-cpp options ]
        allows arbitrary CPP definitions which effect plan preprocessing

logic
    release_name = pool_name unless set explicitly
    preprocess plan
        -DRELEASE_NAME=...

    filter out all comments
    calculate package set from plan
        add packages that don't start with !
        remove packages that start with !
            if package doesn't exist in set, ignore

    print ### from plan
    for each package in plan:
        skip if package already handled

        get_package_spec():
            get package from pool
                raise exception if we can't
            extract deps and version 
            for each package in deps:
                skip if package already handled
                get_package_spec(package)

            print package=version
        
    if bootstrap argument
        print ### from bootstrap
        calculate bootstrap plan (dpkg -l)
        for each package:
            skip if package already handled
            get package from pool
                raise exception if we can't
            extract version of package

            print package=version</t>
<t tx="loni.20110911164714.2">* fab-spec-install &lt;pool&gt; &lt;spec&gt; &lt;chroot&gt;
gets packages from the &lt;pool&gt; according to the &lt;spec&gt; and installs them into the &lt;chroot&gt;

environment variables
    FAB_POOL_PATH               lookup paths for a relative pool path
        e.g.,
            FAB_POOL_PATH=/turnkey/fab/pools

&lt;pool&gt; := relative/path | /absolute/path
    if relative/path, pool is looked up in FAB_POOL_PATH

&lt;spec&gt; := /path/to/spec | -
    if spec is `-' reads spec in from stdin

logic
    mount required virtual filesystems in chroot
        /proc /dev/pts

    copies packages according to spec from the pool to chroot 
        raises exception on error (e.g., if we can't get a package according to the spec)

    installs all the packages with dpkg
        raises exception if dpkg fails (e.g., missing dependency, configure failure, etc.)

    prints dpkg output to stdout

    unmount virtual filesystems in chroot (if we mounted them ourselves)</t>
<t tx="loni.20110911164714.3">* fab-apply-removelist &lt;remove-list&gt; &lt;path&gt;
remove files and directories as specified by &lt;removelist&gt; from &lt;path&gt;</t>
<t tx="loni.20110911164714.5">* fab-plan-lint [ -options ] &lt;pool&gt; &lt;plan&gt; [ ... ]
pretty print each package in the plan with its short description as a comment

&lt;pool&gt; := relative/path | /absolute/path
    if relative/path, pool is looked up in FAB_POOL_PATH

&lt;plan&gt; := /path/to/plan | -
    if `-' read plan from stdin

environment variables
    FAB_TMPDIR env var
        defaults to TMPDIR or /var/tmp if not set

    FAB_POOL_PATH               lookup paths for a relative pool path
        e.g.,
            FAB_POOL_PATH=/turnkey/fab/pools

options
    -i          edit plan in-place

logic
    if -i, redirect print output to temporary file

    parse plan into lines
    for each line:
        if only comment / new line, print and skip to the next line
        parse package name
        get package from pool into TMPDIR
        raise exception if get fails
        extract short description
        print package name + "#" + short description
    
    if -i, copy temporary file over plan</t>
<t tx="loni.20110911180234">fab-cpp is an internal command, called by fab-plan-resolve

-----------------------/
fab-cpp [-options] &lt;plan&gt;

Pre-process a plan (internal command)

Arguments:
  &lt;plan&gt;                path to read plan from (- for stdin)
  
Options:
  --cpp=                 options to pass directly to the C Preprocessor

-----------------------/

cpp -I&lt;FAB_PLAN_INCLUDE_PATH&gt; &lt;plan&gt;
    eg.
    cpp -I/turnkey/fab/common-plans plan/main
    
Q: how do i pass the plan i read from stdin to CPP?
A: cpp will read from stdin if '-' is specified
    note: if no infile not '-' is specifed, stdin is specified as default
    
IDEA:
    read in plan, whether file or stdin
    pass "plan contents" to cpp on stdin
    eg.
        cat plan/main | cpp -I/turnkey/fab/common-plans
        
problem: local includes aren't found, we have to give the path
    cat plan/main | cpp -I/turnkey/fab/common-plans -Iplan
    
Q: should fab-cpp have options, such as -I, -D, etc?
    we could have multiple include options, how would we handle that?
    
    IDEA: have option called --cpp="" to pass options directly to cpp


&lt;plan&gt; | cpp -I&lt;FAB_PLAN_INCLUDE_PATH&gt; &lt;CPP_EXTRA_OPTIONS&gt;


</t>
<t tx="loni.20110912121610">the word "linux" is being replaced by the number 1 with a space:
    s/linux/1 /

    $ echo linux-test | cpp
    # 1 "&lt;stdin&gt;"
    # 1 "&lt;built-in&gt;"
    # 1 "&lt;command line&gt;"
    # 1 "&lt;stdin&gt;"
    1 -test


It seems "linux" is a macro, with a definition of 1.

Solution: redefine the macro

    $ echo linux-test | cpp -D linux=linux
    # 1 "&lt;stdin&gt;"
    # 1 "&lt;built-in&gt;"
    # 1 "&lt;command line&gt;"
    &lt;command line&gt;:1:1: warning: "linux" redefined
    &lt;built-in&gt;: warning: this is the location of the previous definition
    # 1 "&lt;stdin&gt;"
    linux-test


Better Solution: undefine the macro

    $ echo linux-test | cpp -U linux
    # 1 "&lt;stdin&gt;"
    # 1 "&lt;built-in&gt;"
    # 1 "&lt;command line&gt;"
    # 1 "&lt;stdin&gt;"
    linux-test

Q: should we add this to fab-cpp?
A: no, it should be added by the user of fab-cpp, along with any other cpp options he wishes
</t>
<t tx="loni.20110912123550">fab-plan-resolve [ -options ] &lt;pool&gt; &lt;plan&gt; [bootstrap.spec]

Resolve plan into spec using the latest packages from a given pool

Arguments:
  &lt;pool&gt;                Relative or absolute pool path
                        If relative, pool path is looked up in FAB_POOL_PATH
  &lt;plan&gt;                Path to read plan from (- for stdin)
  bootstrap.spec        Path to spec of packages to not be included in root.spec
  
Options:
  --output=             Path to spec-output (default is stdout)
  --cpp=                Arbitrary CPP definitions to effect plan preprocessing


-----------------------/

bootstrap
---------
i don't know how we will be creating the bootstrap, so currently i 
am using a dropin created with oldfab.

to get around the need for root privs to get a list of packages in the bootstrap (dpkg -l), 
or getting the list from a bootstrap source list (not decided upon yet), i have also created
a list manually created with dpkg -l.

i then turned the list into a bootstrap.spec, which will be used by resolve-plan
root.spec will _not_ include packages in the bootstrap.spec





TODO:
    support bootstrap argument
    update Makefile
    
    clean up code
    
    move onto fab-spec-install...
    

logic
    release_name = pool_name unless set explicitly
    preprocess plan
        -DRELEASE_NAME=...

    filter out all comments
    calculate package set from plan
        add packages that don't start with !
        remove packages that start with !
            if package doesn't exist in set, ignore

    print ### from plan
    for each package in plan:
        skip if package already handled

        get_package_spec():
            get package from pool
                raise exception if we can't
            extract deps and version 
            for each package in deps:
                skip if package already handled
                get_package_spec(package)

            print package=version
        
    if bootstrap argument
        print ### from bootstrap
        calculate bootstrap plan (dpkg -l)
        for each package:
            skip if package already handled
            get package from pool
                raise exception if we can't
            extract version of package

            print package=version</t>
<t tx="loni.20110916154247">
pool-get can't/doesn't get a package requested if the package name is provided by a package
eg. perlapi-5.8.7 (dep via dep of casper)
    is provided by perl-base

possible solutions:
    * fork the packages that depend on "provided" packages
    * add functionality to pool
    * add functionality to fab
    * add a virtual package
    * add a meta-package to the package pool


we can't "get_package_spec" of a virtual package
eg. libapt-pkg-libc6.4-6-3.53 (dep of apt-utils)

</t>
<t tx="loni.20110917153918">fab-spec-install &lt;spec&gt; &lt;pool&gt; &lt;chroot&gt;

Installs packages from given pool in chroot according to the spec

Arguments:
  &lt;spec&gt;                Path to read spec from (- for stdin)
  &lt;pool&gt;                Relative or absolute pool path
                        If relative, pool path is looked up in FAB_POOL_PATH
  &lt;chroot&gt;              Path to chroot


-----------------------/

rm -rf root.build
cp -a bootstrap root.build
fab-spec-install /turnkey/fab/pools/rocky root.spec root.build


logic
    mount required virtual filesystems in chroot
        /proc /dev/pts

    copies packages according to spec from the pool to chroot 
        raises exception on error (e.g., if we can't get a package according to the spec)

    installs all the packages with dpkg
        raises exception if dpkg fails (e.g., missing dependency, configure failure, etc.)

    prints dpkg output to stdout

    unmount virtual filesystems in chroot (if we mounted them ourselves)
    
oldfab related notes
    20mountpoints
        mount proc-chroot ${FABPROD}/chroot/proc -t proc
        mount devpts-chroot ${FABPROD}/chroot/dev/pts -t devpts
        
    21finalize-bootstrap (maybe this should be in the bootstrap already?)
        echo "do_initrd = Yes" &gt; ${FABPROD}/chroot/etc/kernel-img.conf
    
    install-packages
        create fake start-stop daemon
        inchroot
            chroot ${FABPROD}/chroot /usr/bin/env -i HOME=/root TERM=${TERM} \
                LC_ALL=C PATH=/usr/sbin:/usr/bin:/sbin:/bin \
                DEBIAN_PRIORITY=critical ${1}
        replace fake start-stop daemon with real
    
        note: remove debs
    
    35umountpoints
        umount -f devpts-chroot
        umount -f proc-chroot
        

</t>
<t tx="loni.20110917232324">mass installing via dpkg is failing
    this is due to dpkg not preconfiguring what packages to install in what 
    order, and generating tons of errors
    
    default max errors is 50, i gradually increased the max error amount upto 
    100,000 with --abort-after, but it is still failing... - but different error
    
    we now have a dependency problem.
    
HYPO: bug in plan-resolve?
    Test: setup apt and try the install using apt-get
    Result: yes, i was missing dependencies

manually setup apt
    cd root.build
    mkdir -p dists/rocky/fab/binary-i386
    apt-ftparchive packages fab/ | gzip -9 &gt; dists/rocky/fab/binary-i386/Packages.gz
    echo "deb file:/// rocky fab" &gt; etc/apt/sources.list

    chroot into root.build
        apt-get update
        PKGS=""; for p in $(apt-cache pkgnames); do PKGS="$PKGS $p"; done
        apt-get install $PGKS
    
    IDEA: put the packages directly into /var/cache/apt/archives/

The following packages have unmet dependencies:
  aspell-en: Depends: aspell (&gt;= 0.60.3-2) but it is not installable
  build-essential: Depends: gcc (&gt;= 4:4.1.1) but it is not installable
                   Depends: make but it is not installable
  defoma: Depends: file but it is not installable
  dpkg-dev: Depends: make but it is not installable
  firefox: Depends: fontconfig but it is not installable
  g++: Depends: gcc (&gt;= 4:4.1.2-1ubuntu1) but it is not installable
       Depends: gcc-4.1 (&gt;= 4.1.2) but it is not installable
  g++-4.1: Depends: gcc-4.1 (= 4.1.2-0ubuntu4) but it is not installable
  hal: Depends: dbus (&gt;= 0.60-1) but it is not installable
  liblaunchpad-integration0: Depends: launchpad-integration but it is not installable
  libpango1.0-common: Depends: fontconfig (&gt;= 2.1.91) but it is not installable
  libqt3-mt: Depends: fontconfig but it is not installable
  xbase-clients: Depends: xrandr but it is not installable
                 Depends: bitmap but it is not installable
                 Depends: ico but it is not installable
                 Depends: xf86dga but it is not installable
E: Broken packages


For some reason, the root.spec doesn't have all the packages we need....

Found the issue: bug in the resolve code
    package "abc" would not be added to the package set if a package containing "abc" was already in the set

-----------------

dpkg can't seem to handle figuring out which packages to install in what order.
it keeps on breaking...

Errors were encountered while processing:
 fab/xutils-dev_7.1.ds-6ubuntu1_i386.deb
 fab/libxft2_2.1.12-1_i386.deb
 fab/libxfixes3_4.0.3-1_i386.deb
 fab/libx11-6_1.1.1-1ubuntu3_i386.deb
 fab/xbitmaps_1.0.1-0ubuntu2_all.deb
 fab/libxt6_1.0.5-1_i386.deb
 fab/x11-common_7.2-0ubuntu11_i386.deb
 fab/libdmx1_1.0.2-2build1_i386.deb
 fab/libx11-data_1.1.1-1ubuntu3_all.deb
 fab/xserver-xorg_7.2-0ubuntu11_all.deb

we have to add some intellegence ontop of dpkg.
manually hunting down which debs to install first, i am able to complete the installation 
    Q: why does dpkg fail...?

    Note: fixing dependencies with dpkg
            dpkg -i --force-depends packages...
            dpkg --configure --pending
            &lt;repeat until no errors&gt;
    
    This is a horrible solution, why kludge fixing dependency problems if we can just install packages correctly?

options:
    * figure out the order ourselves
        apt-python  - still have to implement apt related stuff
        scratch     - reinvent the wheel
        
    * leverage a dpkg frontend
        dselect     - interactive ui
        aptitude    - interactive ui
        apt
            - seems to be the least worse option (manual test successful)

leveraging apt will definately work, and wont take too long
downside is that we will depend on apt

at a later stage, we can develop a solution to figure out the the order, and use dpkg


* apt implementation: refer to chanko
    * pool-get outdir=${root.build}/var/cache/apt/archives
    * index outdir and save directly to lists/_dists_local_debs_binary-i386_Packages
    * create sources.list
    * apt-get update
    * get list of packages to install
        * parse the spec
        * apt-cache pkgnames
    * apt-get install $PGKS


    




</t>
<t tx="loni.20110919154516">fab-apply-removelist &lt;removelist&gt; &lt;path&gt;

Removes files and folders as specified by removelist from the path

Arguments:
  &lt;removelist&gt;          Path to read removelist from (- for stdin)
                        Entries may be negated by prefixing a !
  &lt;path&gt;                Path containing removelist entries (ie. chroot)


-----------------------/


fab-apply-removelist removelist root.patched
   

example removelist contents
    /usr/share/locale/
    !/usr/share/locale/en_GB/
    
the above would remove locale/* except for locale/en_GB
note: the files removed are not deleted, but moved out of the path (ie. the chroot)


</t>
<t tx="loni.20110920142423">fab-apply-overlay &lt;overlay&gt; &lt;path&gt;

Applies overlay ontop of path

Arguments:
  &lt;overlay&gt;             Path to overlay
  &lt;path&gt;                Path apply overlay ontop of (ie. chroot)


-----------------------/


fab-apply-overlay overlay root.patched

from oldfab blueprint overrides:

if [ -d ${BP_DIR}/overrides ]; then
        cp -a ${BP_DIR}/overrides/* ${FABPROD}/chroot/
fi


Note: when using deck, just add it as another layer?
      have option?

</t>
<t tx="loni.20110920150432">fab-chroot &lt;chroot&gt; [command]

Executes command in chroot

Arguments:
  &lt;chroot&gt;              Path to chroot
  command               Command to execute in chroot
                        If no command is specified, an interactive shell is assumed
                        
----------------------------/

</t>
<t tx="loni.20110920175636">the following diff was done on rocky backstage, after "recommended packages" where removed

buildingblocks vs. common-plans
-------------------------------
only in buildingblocks
    fvwm
    feh
    hal
    nano
    apt-utils
    debconf-utils
    ucf
    fcron
    slocate

only in common-plans
    kbd


blueprint vs. plan
------------------
only in buildingblocks
    kbd
    
only in plan
    fvwm
    feh
    fcron
    apt-utils
    debconf-utils
    ucf
    hal
    gnupg


summary
-------
after canceling out...


only in buildingblocks
    nano
    slocate

only in plan
    gnupg (we have it in buildingblocks bootstrap, leaving it for now...)

</t>
<t tx="loni.20110920183538">remove dependencies from plans? 
    usplash
    fvwm

usplash-theme-backstage -&gt; usplash-theme-turnkey

add to console
    nano (we need a basic text editor in the console)

</t>
<t tx="loni.20110923145602">spec-install

Interactive Prompt:

If /lib/modules/2.6.20-15-386/kernel belongs to old install
of linux-image-2.6.20-15-386, then this is your last chance to
abort the installation of this kernel image (nothing has been 
changed yet).

If you know what you are doing, and if you feel that this image
should be installed despite this anomaly, Please answer n to
the question.

Otherwise, I suggest you move /lib/modules/2.6.20-15-386/kernel
out of the way, perhaps to
/lib/modules/2.6.20-15-386.kernel.old or something, and then
try re-installing this image.

Stop install since the kernel-image is already installed?

Yes/No ??


Q: Offending package: ?
    linux-image-2.6.20-15-386

    Nope: thats where we get the error, but the package aufs-modules-2.6.20-15-386
    was the culprit, it was unpacked before linux-image*

IDEA: install the linux-image* packages first before any others
</t>
<t tx="loni.20110928121323">* deck uses useraufs, useraufs errors out saying it can't be run by root

Q: should we remove the dependency of root, and either fakechroot or suid fab?
A: no, fakechroot is a deadend, and fab shouldn't be suid
   useraufs can be configured to allow root
   
   /etc/useraufs.conf
      allow_user root
      allow_dir /turnkey/fab

Problem: deck errors out saying that it can't be run by root
GOTCHA: useraufs was installed to usr/bin, and the updated version is installed to /usr/local/bin - deck was using the older version, while manual testing was using the new version - damn waste of time...


IDEA: maybe deck bootstrap/rocky directly to root.build ?


Q: why are we decking bootstrap/rocky to bootstrap, then bootstrap to root.build?
    we aren't making any changes to the bootstrap
    
    maybe do the deck directly
    maybe create the bootstrap.spec from the bootstrap itself?
        why? we create it before creating the bootstrap...
        
        </t>
<t tx="loni.20110928132411"></t>
<t tx="loni.20111001190214">FAB: product fabrication framework

This version of Fab is actually the second generation framework, the first being referred to as oldfab.

The word "Fab" originates from the microelectronics industry. A fab, or fabrication plant is a factory where devices (eg. integrated circuits) are manufactured for one of more customers. A fab is semantically connected to the most cutting edge technological factories in existence (Silicon chip foundries) - hence the relationship to TurnKey ;)

A fab is a very tightly controlled environment (clean room), but instead of keeping out physical impurities (e.g., dust and dirt), the turnkey Fab is used in fabricating systems while tightly controlling "logical" impurities (e.g., security threats, malware, etc.)

These release notes only contain a high-level overview, please refer to the design notes for detailed information, and help from the commands themeselves.</t>
<t tx="loni.20111001190214.2"></t>
<t tx="loni.20111001190214.3"></t>
<t tx="loni.20111009174710"></t>
<t tx="loni.20111009174710.1">rational:
    the product plan might include newer package versions of those already installed in the bootstrap
    we might be getting rid of the "bootstrap" down the line
    the root.spec should include every package in the product.


Syntax: plan-resolve [-options] &lt;plan&gt; &lt;pool&gt;
Resolve plan into spec using latest packages from pool

Arguments:
  &lt;plan&gt;            Path to read plan from (- for stdin)
  &lt;pool&gt;            Relative or absolute pool path
                    If relative, pool path is looked up in FAB_POOL_PATH

Options:
  --exclude=        Path to spec of packages not to be resolved
  --output=         Path to spec-output (default is stdout)
  --chroot=         Path to chroot installed with packages to append to &lt;plan&gt;


Q: how do i get a list of only package names installed in a chroot?
A: dpkg-query --show -f="${Package}\n"

</t>
<t tx="loni.20111010161023">current algorithm: global calculation
    create set of 'yes' and 'no', then subtracts
    
    pro: allows for declaring "retractions" anywhere in the plan, and them sticking
    con: does not allow for inheritance behaviour


new algorithm: interative calculation
    work on one set, add and remove to/from it
    
    pro: allows for redeclaring a package that has been retracted
         useful for modifying included plan segments
    con: retractions will only take effect depending on their ordering
    
IDEA:
    issue warnings if attempting to "retract" a package that is not declared
    
</t>
<t tx="loni.20111121155941"></t>
<t tx="loni.20111121155941.1">BEFORE
$ time fab-spec-get spec-noepochs /turnkey/fab/pools/rocky packages/
real    0m27.099s
user    0m15.465s
sys     0m9.293s

AFTER
$ time ../fab-spec-get spec /turnkey/fab/pools/rocky packages/
real    0m0.206s
user    0m0.136s
sys     0m0.060s


140 times faster!!!

OPTIMIZATION: call pool-get with spec (instead of each package seperately)
</t>
<t tx="loni.20111121155941.2">plan-resolve (synapse, sumo, pool)

BEFORE
real    0m19.148s
user    0m11.101s
sys     0m6.764s

not executing pool-get (pretending it was already executed)
real    0m2.591s
user    0m1.156s
sys     0m0.768s

its taking a long time because pool-get each package seperately.

IDEA:
    dump the whole pool with the latest packages, then calculate the plan   
    we can further optimize by caching package dependencies, so we dont have to unpack and parse debs.
    
    getting the whole pool:

    $ time POOL_DIR=/turnkey/fab/pools/rocky pool-get tmp

    real    0m0.200s
    user    0m0.128s
    sys     0m0.060s

    the downside: we might be building packages we don't need to resolve the plan
        this can become a pain when the packages we dont need are big, and take a long time to build
        eg. kernel, firefox
        
        but, this depends on the pool stock registrations


AFTER
real    0m3.546s
user    0m1.580s
sys     0m1.112s


5.5 times faster!!!

OPTIMATION: dump all packages in pool first, then resolve the plan


plan resolve on the entire backstage plan

BEFORE
real    1m29.078s
user    0m51.559s
sys     0m32.438s


AFTER
real    0m18.576s
user    0m7.456s
sys     0m4.752s


5 times faster!!!

-------------------------------------------

further optimizations

instead of reading the dumped packages from the filesystems each time we want to check for a package
read in the list, and then just query it

AFTER

real    0m11.796s
user    0m5.400s
sys     0m3.276s


---------------------------------------------

further optimizations (refactoring of code)

real    0m7.609s
user    0m4.728s
sys     0m2.816s





</t>
<t tx="loni.20111121182213">we can further optimize by caching package dependencies?
    </t>
<t tx="loni.20111121182213.1">LOGIC
    build set of missing packages
    build set of provided packages

    when there are no more unresolved packages (missing - provided)
        if its not empty - raise an exception with the list of missing packages

    provided can't limit the version

Q: can a package provide multiple virtuals?
A: yes and they do
    grep-available -s Package,Provides -F Provides -e '.'

Package: linux-image-2.6.20-15-386
Provides: linux-image, linux-image-2.6, fuse-module, ndiswrapper-modules-1.9, ivtv-
modules, kvm-modules-2

=== #1 email

handling dependencies in virtual packages

Its best not to include virtual packages in plans directly. They are however
brought in via dependencies. So how do you resolve them without hardwiring
arbitrary mappings?

How about this, you add the virtuals to a deferred list. You `handle' the
virtual packages at the end, after all other packages, and the way you handle
them is to verify that one of the non-virtual packages we already processed
`provides' the virtual package, otherwise you raise an exception.

This way the plan itself specifies which real package to use to satisfy a
virtual package rather than getting this information from some external mapping.
On the other hand, if the plan's developer neglected to `provide' the virtual
package, then an exception is raised stating exactly which virtual is not
provided so that the plan developer can fix this.

To do this you need to be maintain a cache of the control fields extracted from
the packages you are resolving. If you store this cache on the filesystem,
you'll be able to reuse it later when you are installing the spec, so you don'
have to wait for apt-ftparchive to re-extract the control fields from the
packages yet again - which is only necessary because you're using apt instead of
invoking dpkg (yes I understand your rational - documented in the Leo workflow)

=== #2 email

1) If you read section 7.4 - Virtual packages - Provides of the Debian Policy
Manual, you'll see that the terminology I use is in fact correct.

Maybe you are confusing virtual packages with meta packages (packages that are
empty except for other dependencies)?

2) apt handles virtual packages in the same way I am proposing to handle virtual
packages - by asking the user to specifically select a real package to satisfy
the dependency:

# apt-get install awk
Reading package lists... Done
Building dependency tree
Reading state information... Done
Package awk is a virtual package provided by:
  original-awk 2005-04-24-1
  mawk 1.3.3-11ubuntu2
  gawk 1:3.1.5.dfsg-4build1
You should explicitly select one to install.
E: Package awk has no installation candidate

3) I don't understand why you think the pool has the missing info. Only the user
has it.

For example, how could the pool decide whether to install mawk or gawk to
satisfy awk?

I came across various alternatives for handling virtual packages when I was
researching how to automatically resolve build dependencies in deckdebuild.
Debian's alternatives to deckdebuild (which suck pretty bad IMO), solve this
with global configuration maps in which you specify which real packages will
resolve which virtual package, which is probably ok for building packages, but
not for building products. Currently fab does the same thing, only the
configuration map is hardwired into the code.

BTW, deckdebuild solves this by requiring you to properly configure your
buildroot with all the real packages you want so that virtual packages are
already satisfied. Pre-installing build dependencies also saves some time
setting up the buildroot when you build a package.

My design amendment proposes a simple solution - instead of having a global map
(the current solution) or a per-product map, how can we use the existing plan to
describe how to resolve virtual packages? Simple - make sure your plan includes
(either directly or indirectly via dependency) a real package that satisfies the
dependency on the virtual package!

The reason I like this solution is that it doesn't add any extra parts from the
product develops perspective.

4) Yes, solving this problem will inevitably add some complexity to the
plan-resolve logic, but unless you have a better proposal I will claim this is
*essential* complexity (I.e., the kind you have to live with), in which case the
only real question is how to do it in a clean and simple way, not whether to do it.

I'd like to point out that you don't need extra communication lines / new
interface with the pool to get the information you need. If you ask the pool to
dump packages in a new directory (e.g., in --quiet mode so it doesn't litter the
output with too many error messages) then by running debinfo on the new
directory contents you have the set of packages which the pool did give you, and
by subtracting that from the set of packages you asked for, you get a list of
packages which the pool didn't give you, either because they are missing or
because they are virtual packages.

Meanwhile by parsing the Provides header you also get a mapping of which virtual
packages are already satisfied and you can take those packages off your list of
packages that are MIA (Missing in Action).

You don't immediately complain in the first pass because maybe the virtual
package is resolved (I.e., via non-virtual dependency) by a package you'll only
get from the pool via a non-virtual dependency in later passes.

Only when you have finished the final pass and there are still missing packages
in your list that haven't been resolved - you complain that the packages are
missing from the pool (it doesn't really matter whether they are virtual
packages or real packages).

If you have a better idea, lets hear it.





</t>
<t tx="loni.20111121190436">At least your suggestion is safe, though I don't like how it adds redundant
cruft to the Makefile (you need to use that little trick over and over again on
all sections of the Makefile).

Ultimately, while your suggestion does take care of the safety issue, its still
not optimal because you will still be redoing that Makefile step from the
beginning. This can take a while depending on the size of the job and when the
error happens (beginning, middle, one step before the end?).

As I mentioned in the optimization HOWTO, one way to optimize a process is to
figure out how to reach the same result in less steps.

What if instead you enabled safe transparent auto-resume/continue support for
plan-resolve and spec-install? It will add some complexity but I think its more
than worth it. If a failure happens in your product build (e.g., package FTBFS 
(Fails To Build From Source)),
you can fix it and immediately get on with the product build. You don't have to
wait until you rereach that error to know if your fix worked or not. This
should shorten the development cycle. Especially if you implement this in
addition to other performance optimizations (e.g., caching of repeated operations).

In principle both of these commands (plan-resolve and spec-install) spend their
time looping a list of batched "transactions", and having successfully completed
a given transaction, move on to the next.

So you could, at least in some cases, safely skip all of those successfully
completed transactions instead of starting over and redoing all the steps from
the very first transaction. To do that you need to save some state such that if
they are rerun with the same inputs after being prematurely aborted, they will
fast-forward through all the successfully completed transactions to the
transaction that failed.

Some implementation considerations:
* we need to safely handle changing inputs so if for example the plan or spec
changes, the resume state is invalid, and we discard it and start from the
beginning. In particular, for plan-resolve this means we check the validity of
the finalized transaction list (I.e., after preprocessing and after handling of
packages from --chroot)

* You don't actually need to save the input contents to determine
whether they have changed since the last aborted operation. You only need a hash
of the inputs. This simplifies the contents of the resume state object to
include only two simple parameters:
	1) hash of inputs
	2) last successfully completed transaction

* allow continue support/autoresume to be turned off: --noresume

Which should be the default (I.e., resume or noresume)?

From a quick consideration, I think safe resume support would be a reasonable
default mode of operation with a couple of exceptions (described below)

If you discover it isn't safe, you could require the user to explicitly turn on
auto-resume with the --resume option

* for plan-resolve, if the output is not to a file, we can't resume safely,
because there is no way to ensure we are appending to the output pipe (you can
do that with a file by opening it in append mode).

In other words, the user might be executing plan-resolve and piping it to a file
or program in a way that is inconsistent with resume logic. So by default, if
the output is not a file, we should disable resume support.

In other words, for plan-resolve the default is whatever is safe depending on
the circumstances. If we're outputting the resolved plan to a file, the default
is to resume unless the user asks for --noresume (I.e., its the most convenient
safe thing to do). On the other hand, if we're outputting the resolved plan to a
pipe (e.g., stdout), then the default is to not resume unless the user asks
explicitly to --resume because thats the only safe thing to do.

Naturally, both options and their defaults should be carefully described in the
embedded documentation.

* for spec-install, I think having `resume' as the default would be safe
assuming the spec hasn't changed of course (otherwise the resume state is
invalid). If this is true, you don't actually need --resume option here at all,
just --noresume.

* suggestion for the location and format of the resume state file

location:
	statefile = join(dirname(output), ".%s:RESUME" % basename(output))

e.g.,
	if output=="rocky.spec":
		statefile=".rocky.spec:RESUME"

format := "&lt;input-hash&gt; &lt;resume-from-index&gt;"
	e.g.,
		d456306e2be4decb08ecc34f9c05f448 1
		If resume-from-index is 1, we skip the first transaction (0).

&lt;input-hash&gt; := hash of inputs
&lt;resume-from-index&gt; := index of the transaction we resume from
	the first valid value is 1

* the resume state file needs to be updated with every successful transaction.
the first

* the resume state needs to be deleted when the last transaction finishes

If you accept the proposal, you can add it to the Leo and implement it. Comments
welcome.

</t>
<t tx="loni.20111206170905">Q: where should it be implemented?
Q: should it be self contained?

if we create it as a product (/turnkey/fab/products/fabregtest)
    we can then deck bootstrap for proper testing

the best and most complete fab test is to fabricate a product
the regression suite should provide quick testing and confirmation that nothing is broken


IDEA:
    create a source package which creates lots of binary packages
    those binary packages will provide the testing infrastructure
    
Packages
    no depends
    depend by name
        available
        not available
    depend by each relation version: &lt;&lt;, &lt;=, =, =&gt;, &gt;&gt;
        available
        not available


</t>
<t tx="loni.20120103150913">Slim builds fine with it, but backstage chokes.

Unpacking linux-image-2.6.20-15-386 (from .../linux-image-2.6.20-15-386_2.6.20-15.27_i386.deb) ...
Ok, Aborting
dpkg: error processing /var/cache/apt/archives/linux-image-2.6.20-15-386_2.6.20-15.27_i386.deb (--unpack):
 subprocess pre-installation script returned error exit status 1
Selecting previously deselected package linux-image-386.
Unpacking linux-image-386 (from .../linux-image-386_2.6.20.15.14_i386.deb) ...

</t>
<t tx="loni.20120124160345">1) -p --pool
A mandatory option, with the default being set by the POOL environment variable.

Specifying the pool in the command line (e.g., -p /turnkey/fab/pools/rocky),
overrides the POOL environment variable.

Rational:
* makes it easier to use fab-plan-resolve and fab-spec-install interactively,
for development/debugging purposes.
* the pool is not input so much as a configuration/context in which the fab
operates.
* cleans up the argument list in the Makefile

$ export POOL=/turnkey/fab/pools/rocky
$ fab-plan-resolve plan/main
$ fab-plan-resolve plan/main bootstrap


affected commands:
    plan-resolve [-options] &lt;plan&gt; &lt;pool&gt; [ /path/to/bootstrap ]
    plan-lint [-options] &lt;plan&gt; &lt;pool&gt;
    spec-install &lt;spec&gt; &lt;pool&gt; &lt;chroot&gt;
    
    
</t>
<t tx="loni.20120124164315">2) fab-spec-install -&gt; fab-install

I would like to extend and generalize the functionality of fab-spec-install so
it can install plans and package names as well.

Usage scenarios:
$ fab-install root.patched jed

Will resolve all of the dependencies for the latest version of jed in the pool
and install all of them into root.patched. This should be equivalent to
something like (assuming 1 has already been implemented):

	echo jed &gt; tmp-plan
	fab-plan-resolve tmp-plan &gt; tmp-spec
	fab-spec-install tmp-spec root.patched

$ fab-install root.patched xjed jed

Installs more than one package into root.patched

$ fab-install root.patched jed=1.2.3

Will "resolve" all of the dependencies for this specific version of jed in the
pool and install all of them into root.patched.

$ fab-install root.patched root.spec

Recognizes that root.spec is a file and processes it accordingly.

Equivalent to:
	fab-install root.patched $(cat root.spec)

$ fab-install root.patched plan/main

Does what you would expect.

Note that this would eliminate the distinction between specs and plans for
fab-install, which would magically support both.

I think this is the right thing to do.

-----------

fab-install would be the result of merging plan-resolve and spec-install

if fab-install replaces fab-spec-install to install root.spec, then we will be resolving every package in the spec, which was originally resolved by plan-resolve - in other words it would waste time

IDEA: have an option to not resolve dependencies
    an error will be raised if we try install a package that has dependendencies, and they are not already installed...

    --dont-resolve
    --no-deps
    --nodeps

Design change:
    instead of specifying a path/file as an argument, a cleaner implementation would be to have -i --input, like pool does, and consistency is always good. ;)


====================

Syntax: install [-options] &lt;chroot&gt; [ package[=version] ... ]
Install packages into chroot

If a package is specified without a version, install the newest version.

Argument:
  &lt;chroot&gt;          Path to chroot
    
Option:
  -i --input &lt;file&gt; File from which we read package list (- for stdin)
  -p --pool         Mandatory: Relative or absolute pool path
                               Defaults to environment: POOL
  --no-deps         Do not resolve and install package dependencies


</t>
<t tx="loni.20120124212451">fab-install must be able to process plans
plans must be resolved, and cpp processed

cpp problem:
    current cpp code takes plan as plan_path, not plan data
    
    solutions:
        in fab-install, when we get path/file as input, use that
            no - that means we can't get plan as stdin
            
        write data to temp file, and pass that to cpp
            easiest solution, but ugly workaround
            
        update cpp code to pass data via stdin if its not a file


</t>
<t tx="loni.20120125090839">i don't like the kludge code added to support stdin, it has manifested itself throughout the code...

if we really need it in the future, i will add it back in a better way...


Syntax: %s [-options] &lt;chroot&gt; &lt; inputfile | package[=version] ... &gt;

Argument:
  &lt;chroot&gt;          Path to chroot
    
Option:
  -p --pool         Mandatory: Relative or absolute pool path
                               Defaults to environment: POOL
  --no-deps         Do not resolve and install package dependencies
  
</t>
<t tx="zaril.20110904173229">@nocolor
</t>
<t tx="zaril.20110904173337"></t>
<t tx="zaril.20110904173337.1">* REMINDER: design principles
do simplest thing that could work
let the future take care of itself

* IDEAS
use dpkg's --root=&lt;dir&gt; option to set root
    chroots into &lt;dir&gt; in order to run installation scripts

add option to deck that only unmounts submounts?

* QUESTIONS
Q: what is the name of the system?
A:
    fab for short
    product fabrication framework
---
Q: name of subcommand that creates the spec from the plan?
A:
plan-resolve
    goes nicely with plan-lint

alternatives
    make-spec
    
    resolve
    resolve-plan
    make-spec
    create-spec
    implement-plan
    calc-spec
    compile-spec
    compile-plan
    process-plan
---

Q: name of subcommand that applies the spec to a bootstrap?
A:
spec-build
---
Q: suffix for plan files?
A: no suffix, identify plan files by context (in their own directory)
---

FUTURE

Q: what is the workflow for recreating a recipe?
---
Q: how to handle required/base bootstrapping plans?
    two separate non-recursable plans?
    eliminate the base list, stay with just the required?
        pass that to debootstrap?
</t>
<t tx="zaril.20110904173337.3">product := the final product used by the end-user
    a product is created by formatting the `patched root' according to the format configuration
        example format types (inspired by rpath)
            CDROM ISO
            network bootable PXE image
            root tarball
            vmware workstation image
            vmware ESX image
            Xen image
            Parallels image

    a product can be generated automatically in multiple forms

the patched root := the chroot'able root filesystem of a product, patched manually or automatically
    can be re-created automatically by applying the root patch as an overlay to `the root'

the root patch := an overlay recording any changed performed by manual or automatic means to `the root'
    distributed as a tarball in `the recipe'

the root := the chroot'able root filesystem of a product
    built by applying the `root spec' on the `bootstrap'

a build := a filesystem created from a `spec'
    e.g., root build, bootstrap build
    
    in the correct context, build is implied if it is dropped
        e.g., `root' means `root build'

the bootstrap := the minimal chroot'able filesystem used to bootstrap the root
    built from a bootstrap spec

a plan := a set of package names (I.e., see Python's set construct)
    plan types:
        root plan := the recursable plan from which we create the root spec
            recursable means we lookup the dependencies of listed packages recursively
        
        bootstrap plan = the non-recursable plan from which we create the bootstrap spec
            non-recursable means no recursion of the plan 
        
            due to implementation constraints may need to be separated into two parts (required, base)
                hopefully not

    plans = buildingblocks + blueprint's packages file
        building blocks term has been eliminated
        plan grouping has been implemented in a more flexible, generic way (cpp)
            a single plan (e.g., for backstage) can support multiple `releases' (sphinx, rocky)

a spec := a set of (package name, package version) tuples
    a spec is created from a plan against a specific pool
        the same plan will generate different specs against different pools

    plan types:
        root spec := the spec from which the root is built
        bootstrap spec := the spec from which the bootstrap is built
            due to implementation details, may need to be separated into two parts
                e.g., required and based (for debootstrap)
            
                preferably there could be some way simplify this into one list
        
product recipe := a light bundle of data from which a product can be recreated from source
    a product recipe is created during the creation of a new product
        by recording the outputs of the build
            bootstrap spec
            root spec
            root patch
            product format configuration</t>
<t tx="zaril.20110904173337.4">* global environment variables 
    FAB_PLAN_INCLUDE_PATH       global include path for plan preprocessing
        e.g.,
            FAB_PLAN_INCLUDE_PATH=/turnkey/fab/common-plans
        
    FAB_POOL_PATH               lookup paths for a relative pool path
        e.g.,
            FAB_POOL_PATH=/turnkey/fab/pools

    FAB_TMPDIR                  where fab utils store temporary files (defaults to TMPDIR or /var/tmp)
</t>
<t tx="zaril.20110904173337.5">REMINDER: converting buildingblocks to plan

perl -i -pe 's/^ \* //; s/==/##/g; s/\((.*?)\)/\1/g'    </t>
<t tx="zaril.20110904173337.6">* RESOURCE: info make

export FOO
	export FOO to sub-programs

override FOO = value
	ignore user-set value for FOO (I.e., passed as argument)

FOO ?= bar
	set FOO to bar only if FOO is not already set

FOO := bar
	expanded

FOO = bar
	recursively expanded

* QUESTIONS
Q: can directories be targets?
A:
    yes
    target must assume directory already exists
        rule is executed if dependencies are newer than the directory
        touch directory to update its modification time
        changing contents of existing file in directory does not change its mod time
---
Q: is there a difference between target and target/
A: yes, target/ is unreliable, use target instead
---
Q: are Makefile variables set in the environment
A: no, unless .EXPORT_ALL_VARIABLES is used, or the variable is exported

    not exported (by default)
        FOO=bar
    exported
        export FOO=bar
---
Q: how are cli variables handled differently?
A:
    variables passed on the cli seem to forcefully override the Makefile's variables

    experiment

        Makefile
            FOO = not changed
            env:
                echo $(FOO)
            
        FOO=changed make env
            not changed
    
        make env FOO=changed
            changed
---

Q: how do we access environment variables in the Makefile?
A:
    all variables in the environment are already set in the Makefile
    experiment
        Makefile
            env:
                @echo $(FOO)
    
        FOO=foo make env
    
---
Q: how do set a default value only if the variable has not yet been defined in the environment
    I.e., environment definition takes precedence over local definition
A:
    Makefile
        FOO ?= foo
    
        env:
            @echo $(FOO)
    
    FOO=bar make env
        bar

  </t>
<t tx="zaril.20110904173337.7"># echo hello &gt; file
# make clean
# make
# rm -rf foo
# make (should recreate foo.copy)

all: foo.copy

clean:
	rm -rf foo/ foo.copy/

foo: file
	mkdir -p $@
	cp $&lt; $@

foo.copy: foo
	cp -a $&lt; $@
</t>
<t tx="zaril.20110904173519">new design disintegrates fab into multiple independent layers

fab phases
    make bootstrap
        context: new bootstrap created per-release
            can be recreated at any time from bootstrap spec
    
        steps
            make bootstrap-spec # only if creating new bootstrap
                inputs: pool, bootstrap plan
    
            make bootstrap
                inputs: pool, bootstrap spec
    
    make root
        context: performed per-product
    
        steps
            make root-spec # only if creating a new root
                inputs: pool, bootstrap, root plan
    
            make root
                inputs: pool, bootstrap, root spec
    
    make root patch
        output: tarball of the overlay created
    
        more than one way to create root patch
            manually (e.g., with deck)
            automatically
                apply overrides/removes
                run hook scripts which perform arbitrary changes on the root
                    e.g., this is one way we could implement licop-like `activation'
            hybrid (automatic changes + manual changes)
            
    make product
        inputs: patched root + format configuration
        a single patched root may be formatted into multiple format types
    
product build workflow
    how its different
        new design is local, old design is global
            in the new design building is not performed in a global context
                e.g., we don't dump builds to /turnkey/fabarea
    
    we build products using the same workflow and tools used to build compiled software
        building performed per-product, each product in its own directory
        we leverage make to implement the `build pipeline'
        the build source for each product distributed via Git
        .gitignore build products
    
        standard Makefile structure (I.e., standard targets like debian/rules)
    
        decrease repetition of standard tasks via
            debhelper equivalents for the build process
            included Makefile fragments (I.e., like Debian's CDBS)
    
        outputs for each product
            the formatted product itself
            a recipe that can be used to automatically reproduce the product
                properties of the recipe
                    very small footprint compared to the product
                    accurate enough to recreate product from sources bit for bit
                                
pool design changes
    pool can now be configured to include other pools
        GOTCHA: circular dependencies need to be checked for and prevented
            when a user asks to register pool A into pool B
                list all sub-pools in pool A recursively
                if B is already included, raise an exception
                    (we can't have B can't including itself...)
        
    fab programs will not support multiple pools - will work with only one pool
        pool will be configured as an absolute path or relative path
            relative paths looked up in POOL_PATHS
                e.g.,
                    POOL_PATHS="/turnkey/pools"

        Q: how do we set which pool a program is supposed to work with?
        A: IDEAS
            command line option            

            passed to the program via an environment variable
                POOL="rocky"
    
                environment can be overridden via standard command lineoption
                    --pool rocky
                    --pool /turnkey/pools/rocky
        
        also configurable via command line option

plans
    goals: 
        support re-use of package grouping
        support per-release configuration of changes to re-usable package groupings
    
    plans leverage cpp (c pre-processor)
        grouping achieved via cpp includes
        global include paths should configurable
            #include &lt;global/path/to/plan&gt;
    
            from cli 
                -I/path/to/includable/plans
            from environment variable
                PLAN_INCLUDE_PATH
            
        local includes paths should be relative
            #include "relative/path"
            
        we can use CPP to implement global release profiles
            per-release
        
        embed release-specific ifdef statements in package groups
            ifdef triggered by release profile which is triggered by the pool name
    
    linting program adds package short description as comments
        support editing in-place or output to stdout
        works on pre-processed and non-preprocessed plans
    
    plan format
        &lt;package&gt; # this adds the package to the plan set
        !&lt;package&gt; # this removes the package (which may have been included earlier) from the plan set</t>
<t tx="zaril.20110904181421">ROADMAP
    fab-cpp    
    fab-plan-resolve
    
    bootstrap dropin
    fab-spec-install

    fab-apply-overlay

    fab-apply-removelist
    fab-plan-lint

    integrate deck support
    full logging and re-fab support from specs
    
    non-root support?
        fakeroot, fakechroot
        suid wrappers for critical tasks?

</t>
<t tx="zaril.20120115021505">recipe := a light bundle of data from which a product can be recreated from source

a product recipe is created during the creation of a new product
    by recording the outputs of the build
        bootstrap spec
        root spec
        root patch
        product format configuration</t>
<t tx="zaril.20120115021505.1"></t>
<t tx="zaril.20120115021505.2">* use dpkg instead of apt when installing packages
* ideas:
        * debootstrap scripts
        * spec analysis code</t>
<t tx="zaril.20120115022049">










</t>
<t tx="zaril.20120115022333">
problem: there doesn't exist a decent mechanism for annotating plans?
GOTCHA: if we implement our own comment stripping format, we'd have to process include files ourselves

solution: use c-style comments
    c-style comments? (both styles)
        //
        /* */



   </t>
<t tx="zaril.20120115022525">* EMAIL EXCERPT/OVERVIEW

When we reach production, we can change the plan so that the development bits of
a product are included conditionally during preprocessing, depending on a
product.mk variable. Even then I think the default should still be optimized for
development builds because they are more common than production/release builds.

* SUMMARY
allow configuration variables to influence the build process
        product Makefile (e.g., post/pre hooks)
        plan conditionals (during c-preprocessing)
        patch configuration scripts

VAR1 = y
CONF_VARS = VAR1 VAR2 VAR2


test:
    debug on by default

    make root.spec DEBUG=0

roadmap
    debug with just the plan
    pass to conf scripts
        test script shows debug status

INSIGHT: we can influence the cdroot using /pre or /post hooks

RELEASE should be built-in

</t>
<t tx="zaril.20120115022525.1">* SUMMARY
two components
    fab-chroot
    product.mk changes

fab-chroot
    fab-chroot -f?
        or maybe cat script | fab-chroot
    
        cat script | fab-chroot root.tmp
    
    fab-chroot -q (don't print command?)
        quiet
    
    parse the shebang to decide where to pump it to
        if no shebang, pump it to default
   
product.mk
    looks for conf.d
        if it exists, executes everything in it that is mode 755
            using fab-chroot -f -q conf.d/script

    part of creating root.patch after applying the overlay

no inheritance mechanism for now

* TESTS
hello world in default (dash?), bash, python, perl
non-executable

* IDEAS
Q: what do about false exits from fab-chroot?

Q: do we need to mount filesystems for each script?
A: no, if we need to mount filesystems we can do that in one of the scripts

Q: what do we call the scripts directory?
    scripts.d
    conf.d
    post.d
    patch.d
    custom.d

* inheritance IDEAS

let the future take care of itself

union mount/deck + overlay
allow this to be done by overriding the Makefile

if conf.d is "built" by merging components, does it have to be in build?

prevent code duplication by calling code inside the chroot
    install non-trivial setup scripts inside packages

Q: how do we allow inheritance?
    I.e., we probably wouldn't want to reimplement scripts over and over again
    it needs to be gittable?

maybe create scripts directory that is inherited and overridden?
    BASE_SCRIPTS

Q: how do we share scripts between products?
   
</t>
<t tx="zaril.20120130143450.2">Q: recommended or suggested?
A:
    Suggests, because it is perfectly reasonable to use fab to build root filesystems and not package them into ISOs

    Recommended

cdrkit
squashfs-tools?

Recommends

    This declares a strong, but not absolute, dependency.

    The Recommends field should list packages that would be found together with this one in all but unusual installations.

Suggests

    This is used to declare that one package may be more useful with one or more others. Using this field tells the packaging system and the user that the listed packages are related to this one and can perhaps enhance its usefulness, but that installing this one without them is perfectly reasonable.
</t>
<t tx="zaril.20120130153104">no, but we could/should make it easy to use deck to do this

use deck to do that?
deck could show contents of layer?
</t>
<t tx="zaril.20120204022939">logic:
    substitute multi-line comments for tags
    parse the plan line by line
    skip any lines that start with a comment (any type)
    skip lines are already commented
    if no comment exists on a line, add package description as comment

* RANDOM IDEAS
if its already commented - don't add a comment
    e.g., only comment uncommented packages

    don't update package descriptions
        if the user wants the package description to update he can delete the old comment

use different comments for plan-lint package descriptions and different comments for manual comments

    # lint package description
    // manual comment
    /* manual 
    comment */

    Q: how would we handle mixing of comment styles?

use a prefix for lint comments

// @ package description
# lint: package description

# desc: package description

Q: does lint ignore CPP directives?
</t>
<t tx="zaril.20120204023832">I just noticed an opportunity to clean up the boot sequence and optimize it at
the same time.

Most of the casper-bottom scripts can and should be either removed (*) or moved
to product fabrication, to be applied to root.patched:

10adduser
14locales
15autologin (*)
18hostname
19keyboard (?)
22gnome_panel_data (*)
22screensaver (*)
23etc_modules (*)
24preseed
25configure_init
30accessibility (*)
31disable_update_notifier (*)
32disable_hibernation (*)
33disable_binary_drivers (*)
33enable_apport_crashes (*)
34disable_kwallet (*)
35fix_language_selector (*)
40install_driver_updates (*)
41apt_cdrom (*)

(*) - probably best to just remove this altogether

The primary motivation for moving this stuff elsewhere is based on engineering
principles. casper is a global package, and hard wiring Ubuntu's defaults into
all our products is simply wrong. This stuff has to be configurable at a per
product level.

The only scripts that have a legitimate right to exist in casper-bottom are
things that either detected or configured at boot time, such as, for example:

05mountpoints
13swap
20xconfig
23networking</t>
<t tx="zaril.20120204224450">Q: what does casper-reconfigure do?
A: runcommandinroot "$root" dpkg-reconfigure -fnoninteractive --no-reload "$package"
hypo: this is where xresprobe reconfiguration happens

E: try integrity-check</t>
<t tx="zaril.20120204224652"></t>
<t tx="zaril.20120204233609">TODO:

+ separate mounts to a different object?

+ remove --mount option from fab-chroot
    its a completely safe operation
</t>
<t tx="zaril.20120206010049">SUMMARY 
    adding individual scripts (not in conf.d)
        calling fab-chroot --script directly on a single script

    calling run-conf-scripts macro to add another script directory    

Q: how do we apply an additional configuration scripts to root.patched?
A: hook into root.patched/post and apply another one

* IDEAS:

run-conf-scripts product.mk macro
    so that we can add more scripts directories?

maybe even a list of individual scripts?
    we can do that by calling fab-chroot --script directly from a post hook

maybe extend fab-chroot to run script directories?
    this would allow scripts to share code?
        they can share code anyway, just they have to do it in the overlay or in the packages themselves (/usr/share...)



</t>
<t tx="zaril.20120206010657">Inheriting from product.mk is basically very similar to how you inherit from
pyproject's Makefiles (see Appendix for an API reference).

The difference is that fab/contrib/product.mk is designed to be slightly more
flexible and has a better documented API (I.e., make help). You can inherit from
product.mk in a Makefile, but you can also run product.mk as a standalone
program which inherits variable definitions from its environment.

One side effect is that if you inherit from product.mk in a product Makefile,
you can override built-in variables before the include (I.e., they are
conditional assignments), contrary to pyproject's Makefiles in which overriding
built-in variables must be done after the include (because they are not
conditional assignments).

So basically you can safely put everything before including product.mk except
for &lt;target&gt;/body overrides (which should be rarely needed).

=== EXAMPLE

$ cd products/backstage
$ cat Makefile
RELEASE ?= rocky

INITRAMFS_PACKAGES ?= busybox-initramfs casper ectoinitramfs

ifndef FAB_MAKEFILE_INCLUDE_PATH
$(error FAB_MAKEFILE_INCLUDE_PATH not defined)
else
include $(FAB_MAKEFILE_INCLUDE_PATH)/product.mk
endif

=== APPENDIX ===

### extension API

You set the following defines BEFORE including the shared Makefile because
target prerequisites are evaluated at include time:

        &lt;target&gt;/pre  # rules before default body (default: empty)
        &lt;target&gt;/post # rules after default body (default: empty)

        &lt;target&gt;/deps # override default dependencies for a rule
        &lt;target&gt;/deps/extra # extra dependencies for rule (default: empty)

Special case - if you want to override built in built-in rules for a target,
you'll need to define them AFTER including the shared Makefile
        &lt;target&gt;/body # body of rules (default: defined, but can be overridden)

### product.mk API

$ cd fab/contrib
$ make -f product.mk help
=== Configurable variables
Resolution order:
1) command line (highest precedence)
2) product Makefile
3) environment variable
4) built-in default (lowest precedence)

# Mandatory configuration variables:
  FAB_PATH and RELEASE       used to calculate default paths for input variables

# Build configuration variables:
  MKSQUASHFS_COMPRESS        if not an empty string - mksquashfs uses compression
  MKSQUASHFS_VERBOSE         if not an empty string - mksquashfs is verbose

# Build context variables    [VALUE]
  POOL                       $(FAB_PATH)/pools/$(RELEASE)/
  BOOTSTRAP                  $(FAB_PATH)/bootstraps/$(RELEASE)/
  CDROOT                     $(FAB_PATH)/cdroots/bootsplash/
  FAB_PLAN_INCLUDE_PATH      /turnkey/fab/common-plans/
  FAB_TMPDIR                 $(FAB_PATH)/tmp/

# Product input variables    [VALUE]
  PLAN                       plan/main
  ROOT_OVERLAY               overlay/
  CDROOT_OVERLAY             cdroot.overlay/
  REMOVELIST
  CONF_SCRIPTS               conf.d/

# Product output variables   [VALUE]
  O                          build/
  ISOLABEL                   $(shell basename $(shell pwd))

=== Usage
# remake target and the targets that depend on it
$ rm $O/stamps/&lt;target&gt;; make &lt;target&gt;

# build a target (default: product.iso)
$ make [target] [O=path/to/build/dir]
  clean         # clean all build targets
  bootstrap     # minimal chrootable filesystem used to bootstrap the root
  root.spec     # the spec from which root.build is built (I.e., resolved plan)
  root.build    # created by applying the root.spec to the bootstrap
  root.patched  # deck root.build and apply the root overlay and removelist
  root.tmp      # temporary changes here are squashed into a separate layer
  cdroot        # created by squashing root.patched into cdroot template + overlay
  product.iso   # product ISO created from the cdroot

  updated-initramfs # rebuild product with updated initramfs
  updated-root-tmp  # rebuild product with updated root tmp
</t>
<t tx="zaril.20120206010821">
The fab provides 'toolchain' utilities, which allows us to build products and collaborate on them using the same workflow and tools used on software projects.

Building is performed per-product, each in its own directory. We leverage 'make' to implement the 'build pipeline', git and covin for revision control and collaboration.

The output of a product is the product itself, and a recipe (very small footprint compared to the product) which can be use to automatically reproduce the product bit for bit.</t>
<t tx="zaril.20120206010821.1">
product: the final product used by the end-user
    the product is generated by formatting the "patched root"

root.tmp: sandbox for temporary manual experimentation

root.patched: the chroot'able root filesystem of a product
    patched automatically
    can be re-created automatically by applying the root patch as an overlay to `the root'

root.build: the chroot'able root filesystem of a product
    built by applying the "root.spec" on the bootstrap

bootstrap: the minimal chroot'able filesystem used to bootstrap the root
    built from a "bootstrap.spec"

spec: a set of (package name, package version tuples)
    a spec is created from a plan against a specific pool
    the same plan will generate different specs against different pools

plan: set of package names
    root plan
        the recursable plan from which the root.spec is created
        recursable means we lookup the dependencies of listed packages recursively
    
    bootstrap plan
        the non-recursable plan from which we create the bootstrap spec
        non-recursable means no recursion of the plan (this is planned to change)</t>
<t tx="zaril.20120206010821.2">Configuration environment variables:
    FAB_POOL_PATH           Path to the package pool

    FAB_PLAN_INCLUDE_PATH   Global include path for plan preprocessing
    FAB_TMPDIR              Temporary storage (defaults to /var/tmp)

Commands:
    cpp                 Preprocess a plan
    chroot              Executes command in chroot

    plan-annotate       Annotate plan with short package descriptions
    plan-resolve        Resolve plan into spec using latest packages from pool

    install             Install packages into chroot

    apply-removelist    Remove files and folders according to removelist
    apply-overlay       Apply overlay on top of given path</t>
<t tx="zaril.20120206033113">SUMMARY
    symbolic links already work

IDEA: we should be able to change precedence in conf.d without renaming args/&lt;file&gt;

</t>
<t tx="zaril.20120206145455">* IDEAS
manually experiment with which scripts we really need
    by deleting them directly from skeleton's initramfs 

* REMOVE
    10adduser
    14locales
    18hostname
    24preseed
    25confgure_init
    
* DISCOVERY: debconf-set-selections
    debconf-get-selections
    debconf-get-selections | ssh newhost debconf-set-selections
        dumps debconf database to stdout

* INSIGHT: we can/should use isolinux as a runtime configuration mechanism
    get it from /proc/cmdline

remove casper.conf from all products
</t>
<t tx="zaril.20120206152141">* SUMMARY

two programs 
    readahead-list &lt;file&gt;
        loads a list from FILE and performs readahead(2) on each entry

        called by /etc/init.d/readahead
    
    readahead-watch
        called by /etc/init.d/readahead
            if `profile' keyword is in command line
                outputs to /etc/readahead/boot

INSIGHT: in profile mode can be used to generate lists of files read
    with readahead-watch

disabled by casper by default

uses readahead(2) system call?

readahead-watch
    could be used to automatically slim down the CD?

/etc/readahead/ # lists of files to readahead
    boot
    desktop

can be used to implement readahead of a files used to cold reboot
    instead of stupid hack
</t>
<t tx="zaril.20120206161341">IDEA: a package full of useful shell functions
    fatal
    error
    run-scripts
    check if a variable is set</t>
<t tx="zaril.20120206161341.1">SUMMARY
    useradd # create a new user
  
        --create-home
        -g group
        --groups GROUP1,GROUP2,...
        --password CRYPTPASS
        
        -shell
        
        useradd -D
            show default values
                (as in /etc/default/useradd)
        
    usermod # modify user account
        same interface as useradd

INSIGHT: if we want a default password shared by all products we can achieve that via bootstrap    
    
INSIGHT:
    args conf separation overkill in many cases
    we don't need to make everything reusable
    the conf file itself can embed the configuration data
    if the conf file is significantly complex, maybe we need to embed its
        logic in a package
        

set root password

create a user and set its password

the password doesn't have to be encrypted here

as long as its not saved in bash_history

which groups

copy skel

shell


Q: whats the simplest way to achieve that automatically?

Q: should the password be encrypted?

Q: how do I set the root password automagically??


* SCRATCH
</t>
<t tx="zaril.20120207044153">SUMMARY:
    all input directories can be decks
    make redeck updated to redeck them after reboot

IDEA: use deck to implement inheritance?
    e.g., we deck a global location and then delete the stuff we don't want

    Q: how would we deck it automatically?
    A: if conf.d is a deck, we deck it
        same with overlay, plan, cdroot.overlay

IDEA: deck all directory based input to allow inheritance
    decks WOULD hardwire system paths
        they would have to be the same or else

    and we would have to own it

    how would the paths be decked?
        with the redeck target

Q: how can I get redeck to work every time automatically but not add overhead?
A: has to be rerun every reboot
    can we get the reboot information?
        when we booted?</t>
<t tx="zaril.20120207045734">* SUMMARY

  -e --env=VARNAME[: ...]    List of environment variable names to pass through
                             default: $FAB_CHROOT_ENV

Usage example:

  FOO=bar BAR=foo chroot path/to/chroot -e FOO:BAR env

* SCRATCH
-e --environment

--envirnoment

envlist

envacl
envpass

varlist
--varlist

--args

-e --env
FAB_CHROOT_ENVIRONMENT 

env allow
env import

pass in the entire environment?
except for stuff in a blacklist?

exclude

env import

env-include

allow

env-allow

env-deny

formats
    one two three
    one,two,three
    one:two:three



</t>
<t tx="zaril.20120207133732">Q: should we solve the inheritance problem right now?
A:
    no make the scripts as simple as possible
        so duplication is not an issue


</t>
<t tx="zaril.20120208011925">test target: skeleton
</t>
<t tx="zaril.20120208012919">01integrity_check
    if integrity-check in switches

    performs an integrity check comparing files with md5sum signatures on CD
        not a security check but a data corruption test

        I don't think we have the signatures on board

05mountpoints
    moves mountpoints

10adduser
    creates the user based on casper.conf

    move this
        I don't think skeleton needs this anyhow

12fstab
    creates barebones /etc/fstab for live environment

13swap
    tries to detect swap partitions on local machine and activate them

14locales
    move/remove

18hostname
    move/remove

19keyboard
    configures keyboard layout

20xconfig
    runs xdebconfigurator
    reconfigures xserver-xorg package

23networking
    parses netboot.config and creates resolv.conf from it

24preseed
    preseeds installation configuration

        preseed/file=path/to/root/location
        */*=*
            question is */*
            answer is =*
        
            set with casper-preseed
                which uses debconf-communicate
                    sets the value of the question and marks it as seen

    these can be used by
        various scripts
        by the installer
            
25configure_init
     a bunch of hacks 
        disables postfix
        disables readahead-list

    reaches skeleton via boot</t>
<t tx="zaril.20120208060957">by default, append to spec as comments

bootstrap plan &lt;package&gt; &lt;package&gt;* &lt;package&gt;**

order of packages depends on the order they are brought in
</t>
<t tx="zaril.20120208061040">package* # promote recommended
package** # promote suggests + recommended
</t>
<t tx="zaril.20120208061232">accept install arguments outputs Package type formatted output

IDEA: we could mix and match output with grep-dctrl
</t>
<t tx="zaril.20120208061751"></t>
<t tx="zaril.20120208061834">The current logic is to pray that the newest package versions in the pool satisft the dependency restrictions and fail if it doesn't, even if an older version exists in the pool which does satisfy the restriction. This is a naive short term solution.</t>
<t tx="zaril.20120209024252"></t>
<t tx="zaril.20120209024252.1">I've extended fab and product.mk to support product configuration at build-time.
This additional functionality is designed to address a few problems we've been
having:
A) packages shouldn't perform product-specific configurations

For example, casper including scripts that configure users and such at boot time.

This violates separation of concerns and prevents packages from fulfilling their
full utility as generic, reusable building blocks. It also increases the
accidental complexity of the system by introducing unnecessary interdependencies.

Also, there is often significant overhead in changing a package to configure
them to suit a specific product. This is especially true for stock packages, but
generally creating multiple variants of a package just to support different
configurations is inconvenient and time consuming.

B) boot time is not the correct time to perform product configuration

It doesn't scale, it lengthens the boot process and it limits the re-usability
of casper.

C) support adjustments required for different releases with having to
duplicate/fork a plan component

This is the primary reason the new fab design supports preprocessing of plans in
the first place, in order to prevent the kind of inefficient and ugly
duplication of product specifications (e.g., building blocks in "old" fab
terminology) just to support minor adjustments.

D) build development/production variants of a product without having to modify
the product (e.g., remove debug/development packages from the plan).

This allows the simultaneous development of both the "development" version of a
product and the "production" version.</t>
<t tx="zaril.20120209024252.2">Previously the only way to affect product build was to use the "Makefile
inheritance" to add pre/post hooks to targets, or even override the values of
the target "body" and built-in variables.

Configuring a product this way is possible but relatively complex and inconvenient.

I have developed a couple of new powerful mechanisms to support more efficient
product configuration.

1) conf.d/ chroot scripts
2) product configuration variables</t>
<t tx="zaril.20120209024252.3">Any executable script in conf.d (default location, this can be changed) is
copied into a temporary directory in root.patched (after the overlay, but before
the removelist is applied) and executed while chrooted into root.patched. After
execution the temporary directory is deleted.

Any type of script for which there is an interpreter in root.patched is
supported (e.g., shell, perl, python). Static binaries are also supported but
dynamic binaries are dangerous as differences in the library versions in the
chroot may prevent the binary from running correctly, or more likely running at all.

The order of execution of scripts in conf.d depends on the script filename, so
if have to control the order, you can append an integer (e.g., conf.d/10myscript).

The script is executed with arguments extracted from conf.d/args/&lt;name&gt;. By
default, no arguments are passed. This supports re-usability of complex
configuration scripts, but for simple configuration scripts it shouldn't be
needed at all. Note that &lt;name&gt; in conf.d/args doesn't include priority
prefixes, so you can change priority without having to rename conf.d/args/&lt;name&gt;.

Speaking of reusing complex scripts, just like rc*.d scripts, conf.d/ scripts
*can* be symbolic links to shared scripts (e.g.,
/turnkey/fab/common-conf.d/&lt;name&gt;). Whether they *should* be is an entirely
different question and the answer is usually no. Git supports symbolic links
outside of a repository but a hardwired path will still be embedded in the
product's repository, and you know how I feel about hardwired paths.

Pros of sharing configuration scripts:
* could be used to prevent duplication of logic in complex scripts (I.e., write
once fix many times syndrome)

Cons:
* reduces readability: settings need to be separated to args/ or set in the
environment, so its harder to glance at a script and see the whole picture.
* adds significant overhead: parsing of arguments, sanity checking, error
messages, etc.

I think its usually preferable to put complex logic into a package and make the
configuration script as simple as possible by calling the complex functionality
it needs. If a configuration script has good enough primitives to leverage it
can be made simple enough to resemble a configuration file itself. See skeleton
conf.d scripts for an example.

In other words, I think its preferable to avoid sharing configuration scripts
altogether, though I have supported and tested this capability in case we need it.

In case a single conf.d directory isn't enough, its possible to add additional
directories by calling the run-conf-scripts macro in a pre/post hook, like this:

	define root.patched/post
		$(call run-conf-scripts, conf2.d)
	endef

If instead of a directory of scripts you want to execute just a single script in
a pre/post hook, thats also possible. Just call fab-chroot directly:

	fab-chroot $O/root.patched --script path/to/script [args]</t>
<t tx="zaril.20120209024252.4">By setting the following in your product Makefile:

	VAR1 = VALUE1
	VAR2 = VALUE2
	...
	CONF_VARS = VAR1 VAR2 [ ... ]

You are describing a list of configuration variables that will effect:
A) preprocessor definitions in fab-plan-resolve
B) the environment of fab-chroot commands and scripts: the variables listed in
CONF_VARS are exported into their environment.

Note: RELEASE is a mandatory built-in configuration variable. Its added by
product.mk automatically, even if you don't define CONF_VARS at all. This is to
ensure that common-plan components can depend on its existence to effect plan
adjustments required for different releases (e.g., discover1 -&gt; discover2).

For example:

	$ cd skeleton
	$ cat Makefile
	RELEASE = rocky

	CONF_VARS = DEBUG
	DEBUG ?= y # empty string is false

	ifndef FAB_MAKEFILE_INCLUDE_PATH
	$(error FAB_MAKEFILE_INCLUDE_PATH not defined)
	else
	include $(FAB_MAKEFILE_INCLUDE_PATH)/product.mk
	endif

	$ cat plan/main
	#ifdef DEBUG
	#include &lt;debug&gt;
	#endif

	#include &lt;boot&gt;
	#include &lt;console&gt;
	#include &lt;net&gt;

Note that one things configuration variables *don't* effect are overlays, at
least not by default. It is possible however to add this functionality by
defining pre/post hooks which are effected by the value of the configuration
variables.</t>
<t tx="zaril.20120214041118">LOGIC
    a self deleting object


IDEAS
    we can get rid of shutil
    we don't need to mkdir the path we got
</t>
<t tx="zaril.20120226015244">LOGIC
    delete auto-generated comments when annotating and re-annotate
        goal: nice and neat annotation
    
    don't annotate a package if it already annotate with a c style comment on same line
        /* comment */ or // comment
</t>
</tnodes>
</leo_file>
